{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 3*torch.ones((1, 2, 3, 3))\n",
    "x2 = 2*torch.ones((1, 1, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3., 3., 3.],\n",
       "          [3., 3., 3.],\n",
       "          [3., 3., 3.]],\n",
       "\n",
       "         [[3., 3., 3.],\n",
       "          [3., 3., 3.],\n",
       "          [3., 3., 3.]],\n",
       "\n",
       "         [[2., 2., 2.],\n",
       "          [2., 2., 2.],\n",
       "          [2., 2., 2.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReversibleConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, activation):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.act = activation\n",
    "        \n",
    "        self.f = nn.Conv2d(in_channels, in_channels, 3)\n",
    "        self.g = nn.Conv2d(in_channels, in_channels, 3)\n",
    "        \n",
    "    def forward(self, x, requires_grad=False):\n",
    "        if requires_grad:\n",
    "            return self._forward(x)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return self._forward(x)\n",
    "            \n",
    "    def _forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        padding = torch.zeros((n, 2*self.in_channels - c, h, w))\n",
    "        x = torch.cat([x, padding], axis=1)\n",
    "\n",
    "        x1, x2 = x[:, :self.in_channels], x[:, self.in_channels:]\n",
    "\n",
    "        y2 = x2 + self.act(self.f(x1))\n",
    "        y1 = x1 + self.act(self.g(y2))\n",
    "\n",
    "        y = torch.cat([y1, y2], axis=1)\n",
    "        return y\n",
    "    \n",
    "    def reverse(self, y):\n",
    "        with torch.no_grad():\n",
    "            n, c, h, w = y.shape\n",
    "            y1, y2 = y[:, :self.in_channels], y[:, self.in_channels:]\n",
    "\n",
    "            x1 = y1 - self.act(self.g(y2))\n",
    "            x2 = y2 - self.act(self.f(x1))\n",
    "\n",
    "            return torch.cat([x1, x2], axis=1)\n",
    "    \n",
    "rev = ReversibleConv2d(2, F.relu)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = rev(torch.cat([x1, x2], axis=1))\n",
    "    x = rev.reverse(y)\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.0535, 3.0535, 3.0535],\n",
       "          [3.0535, 3.0535, 3.0535],\n",
       "          [3.0535, 3.0535, 3.0535]],\n",
       "\n",
       "         [[3.0000, 3.0000, 3.0000],\n",
       "          [3.0000, 3.0000, 3.0000],\n",
       "          [3.0000, 3.0000, 3.0000]],\n",
       "\n",
       "         [[2.4886, 2.4886, 2.4886],\n",
       "          [2.4886, 2.4886, 2.4886],\n",
       "          [2.4886, 2.4886, 2.4886]],\n",
       "\n",
       "         [[0.0408, 0.0408, 0.0408],\n",
       "          [0.0408, 0.0408, 0.0408],\n",
       "          [0.0408, 0.0408, 0.0408]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `nn.View` not found.\n"
     ]
    }
   ],
   "source": [
    "nn.View?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.4771, 3.4771, 3.4771],\n",
       "          [3.4771, 3.4771, 3.4771],\n",
       "          [3.4771, 3.4771, 3.4771]],\n",
       "\n",
       "         [[4.3360, 4.3360, 4.3360],\n",
       "          [4.3360, 4.3360, 4.3360],\n",
       "          [4.3360, 4.3360, 4.3360]],\n",
       "\n",
       "         [[2.7324, 2.7324, 2.7324],\n",
       "          [2.7324, 2.7324, 2.7324],\n",
       "          [2.7324, 2.7324, 2.7324]],\n",
       "\n",
       "         [[3.9817, 3.9817, 3.9817],\n",
       "          [3.9817, 3.9817, 3.9817],\n",
       "          [3.9817, 3.9817, 3.9817]]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            ReversibleConv2d(2, F.relu),\n",
    "            ReversibleConv2d(2, F.relu),\n",
    "            ReversibleConv2d(2, F.relu),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(36, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        #self.rconv1 = ReversibleConv2d(2, F.relu)\n",
    "        #self.rconv2 = ReversibleConv2d(2, F.relu)\n",
    "        #self.rconv3 = ReversibleConv2d(2, F.relu)\n",
    "        \n",
    "        #self.fc = nn.Linear(36, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.rconv1(x)\n",
    "        #x = self.rconv2(x)\n",
    "        #x = self.rconv3(x)\n",
    "        \n",
    "        act = self.features(x)\n",
    "        x = act.view(act.shape[0], -1)\n",
    "        \n",
    "        return act, self.classifier(x)\n",
    "        \n",
    "    \n",
    "model = Model()\n",
    "y, logits = model(torch.cat([x1, x2], axis=1))\n",
    "    \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[5.9277, 5.9277, 5.9277],\n",
       "           [5.9277, 5.9277, 5.9277],\n",
       "           [5.9277, 5.9277, 5.9277]],\n",
       " \n",
       "          [[3.5798, 3.5798, 3.5798],\n",
       "           [3.5798, 3.5798, 3.5798],\n",
       "           [3.5798, 3.5798, 3.5798]],\n",
       " \n",
       "          [[5.4315, 5.4315, 5.4315],\n",
       "           [5.4315, 5.4315, 5.4315],\n",
       "           [5.4315, 5.4315, 5.4315]],\n",
       " \n",
       "          [[0.2333, 0.2333, 0.2333],\n",
       "           [0.2333, 0.2333, 0.2333],\n",
       "           [0.2333, 0.2333, 0.2333]]]]),\n",
       " tensor([[9.3236e-01, 3.2724e-02, 2.4073e-03, 6.9962e-03, 1.5547e-03, 2.7069e-03,\n",
       "          3.6154e-03, 1.6311e-02, 1.0564e-03, 2.6527e-04]],\n",
       "        grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model(torch.cat([x1, x2], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'rconv3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-071f9c99f1d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print(model.fc.weight.grad.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrconv3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#loss = criterion(logits, torch.LongTensor([0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    583\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 585\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'rconv3'"
     ]
    }
   ],
   "source": [
    "for e in range(50):\n",
    "    model.zero_grad()\n",
    "    y, logits = model(torch.cat([x1, x2], axis=1))\n",
    "    #loss = criterion(logits, torch.LongTensor([0]))\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    \n",
    "    #print(model.fc.weight.grad.shape)\n",
    "    x = model.rconv3.reverse(y)\n",
    "    y_ = model.rconv3(x, requires_grad=True)\n",
    "    #loss = criterion(logits, torch.LongTensor([0]))\n",
    "    logits = F.softmax(model.fc(y_.view(x.shape[0], -1)), dim=1)\n",
    "    #print(logits)\n",
    "    loss = criterion(logits, torch.LongTensor([0]))\n",
    "    loss.backward(retain_graph=True)\n",
    "    #print(model.rconv3.f.data)\n",
    "    \n",
    "    for param in model.rconv3.f.parameters():\n",
    "        print(param)\n",
    "        print(param.grad)\n",
    "    #print(model.rconv3.f.grad)\n",
    "    #print(loss.grad)\n",
    "    #print(y_.shape)\n",
    "    #print(model.rconv3.g.weight.shape)\n",
    "    #print(out_with_grad)\n",
    "    #x = model.rconv2.reverse(x)\n",
    "    #out_with_grad = model.rconv2(x, requires_grad=True)\n",
    "    break\n",
    "    #optimizer.step()\n",
    "\n",
    "#model(torch.cat([x1, x2], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0019, -0.0131,  0.0202],\n",
      "          [ 0.1865, -0.0143,  0.0117],\n",
      "          [ 0.0336, -0.2099, -0.1783]],\n",
      "\n",
      "         [[ 0.1966,  0.1406,  0.0633],\n",
      "          [ 0.1767, -0.0057,  0.0352],\n",
      "          [ 0.0332, -0.1323, -0.0047]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0219,  0.0593,  0.0134],\n",
      "          [-0.2146,  0.1347,  0.2296],\n",
      "          [-0.0963,  0.0125, -0.1721]],\n",
      "\n",
      "         [[-0.0638, -0.1680,  0.0737],\n",
      "          [-0.0928, -0.1373,  0.0640],\n",
      "          [-0.0246,  0.0871,  0.0221]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.0235, -0.0354], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for param in model.rconv2.f.parameters():\n",
    "    print(param)\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.3842, 4.3842, 4.3842],\n",
       "          [4.3842, 4.3842, 4.3842],\n",
       "          [4.3842, 4.3842, 4.3842]],\n",
       "\n",
       "         [[4.8098, 4.8098, 4.8098],\n",
       "          [4.8098, 4.8098, 4.8098],\n",
       "          [4.8098, 4.8098, 4.8098]],\n",
       "\n",
       "         [[2.0000, 2.0000, 2.0000],\n",
       "          [2.0000, 2.0000, 2.0000],\n",
       "          [2.0000, 2.0000, 2.0000]],\n",
       "\n",
       "         [[3.8432, 3.8432, 3.8432],\n",
       "          [3.8432, 3.8432, 3.8432],\n",
       "          [3.8432, 3.8432, 3.8432]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.rconv3.reverse(y)\n",
    "ygrad = model.rconv3(x, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.8032, 4.8032, 4.8032],\n",
       "          [4.8032, 4.8032, 4.8032],\n",
       "          [4.8032, 4.8032, 4.8032]],\n",
       "\n",
       "         [[8.0591, 8.0591, 8.0591],\n",
       "          [8.0591, 8.0591, 8.0591],\n",
       "          [8.0591, 8.0591, 8.0591]],\n",
       "\n",
       "         [[4.4444, 4.4444, 4.4444],\n",
       "          [4.4444, 4.4444, 4.4444],\n",
       "          [4.4444, 4.4444, 4.4444]],\n",
       "\n",
       "         [[4.5945, 4.5945, 4.5945],\n",
       "          [4.5945, 4.5945, 4.5945],\n",
       "          [4.5945, 4.5945, 4.5945]]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ygrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.0000, 3.0000, 3.0000],\n",
       "          [3.0000, 3.0000, 3.0000],\n",
       "          [3.0000, 3.0000, 3.0000]],\n",
       "\n",
       "         [[3.0000, 3.0000, 3.0000],\n",
       "          [3.0000, 3.0000, 3.0000],\n",
       "          [3.0000, 3.0000, 3.0000]],\n",
       "\n",
       "         [[2.0000, 2.0000, 2.0000],\n",
       "          [2.0000, 2.0000, 2.0000],\n",
       "          [2.0000, 2.0000, 2.0000]],\n",
       "\n",
       "         [[0.7503, 0.7503, 0.7503],\n",
       "          [0.7503, 0.7503, 0.7503],\n",
       "          [0.7503, 0.7503, 0.7503]]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.rconv2.reverse(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.0000e+00,  3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00]],\n",
       "\n",
       "         [[ 3.0000e+00,  3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00]],\n",
       "\n",
       "         [[ 2.0000e+00,  2.0000e+00,  2.0000e+00],\n",
       "          [ 2.0000e+00,  2.0000e+00,  2.0000e+00],\n",
       "          [ 2.0000e+00,  2.0000e+00,  2.0000e+00]],\n",
       "\n",
       "         [[-5.9605e-08, -5.9605e-08, -5.9605e-08],\n",
       "          [-5.9605e-08, -5.9605e-08, -5.9605e-08],\n",
       "          [-5.9605e-08, -5.9605e-08, -5.9605e-08]]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model.rconv1.reverse(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.1442]],\n",
      "\n",
      "         [[ 0.4904]],\n",
      "\n",
      "         [[-0.1310]]],\n",
      "\n",
      "\n",
      "        [[[-0.0747]],\n",
      "\n",
      "         [[-0.1755]],\n",
      "\n",
      "         [[ 0.1917]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4958]],\n",
      "\n",
      "         [[-0.0673]],\n",
      "\n",
      "         [[ 0.1109]]]], requires_grad=True)\n",
      "tensor([[[[-0.1442]],\n",
      "\n",
      "         [[ 0.4903]],\n",
      "\n",
      "         [[-0.1309]]],\n",
      "\n",
      "\n",
      "        [[[-0.0747]],\n",
      "\n",
      "         [[-0.1755]],\n",
      "\n",
      "         [[ 0.1917]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4958]],\n",
      "\n",
      "         [[-0.0673]],\n",
      "\n",
      "         [[ 0.1109]]]], grad_fn=<SubBackward0>)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.1685, -0.5070,  0.4180], requires_grad=True)\n",
      "tensor([-0.1684, -0.5070,  0.4180], grad_fn=<SubBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "f = nn.Conv2d(3, 3, (1, 1))\n",
    "g = nn.Linear(27, 10)\n",
    "\n",
    "x1 = torch.randn(1, 3, 3, 3, requires_grad=True)\n",
    "x2 = f(x1)\n",
    "x3 = x2.view(1, 27)\n",
    "x4 = g(x3)\n",
    "x5 = F.softmax(x4, dim=1)\n",
    "\n",
    "loss = criterion(x5, torch.LongTensor([0]))\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "for param in f.parameters():\n",
    "    print(param)\n",
    "    param = param - lr * param.grad\n",
    "    print(param)\n",
    "    print()\n",
    "    \n",
    "for param in g.parameters():\n",
    "    param = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param Parameter containing:\n",
      "tensor([[-0.1507,  0.0685,  0.1473, -0.1457, -0.0130, -0.0834,  0.0090, -0.1046,\n",
      "          0.0056,  0.1236,  0.0417,  0.0204, -0.0993,  0.0575,  0.0794,  0.1457,\n",
      "         -0.1321, -0.1521,  0.1724,  0.0097,  0.1883, -0.0710, -0.1310,  0.0480,\n",
      "          0.0698,  0.0086,  0.0032],\n",
      "        [ 0.1253, -0.1064,  0.1887,  0.1920, -0.0440,  0.1443,  0.0686, -0.0352,\n",
      "         -0.0421,  0.1082,  0.1216, -0.0529, -0.0940, -0.0402, -0.0366, -0.0019,\n",
      "          0.1129, -0.1870,  0.0554,  0.1879, -0.0155,  0.0100, -0.0096, -0.0840,\n",
      "         -0.1593, -0.1181, -0.1414],\n",
      "        [-0.0529,  0.1347,  0.1749, -0.1731, -0.1388,  0.1180, -0.1436, -0.1313,\n",
      "         -0.0232,  0.0972,  0.1711,  0.0590, -0.1325, -0.1796, -0.0495,  0.1057,\n",
      "          0.1130,  0.1734, -0.1355,  0.0049, -0.1907, -0.1782,  0.0547, -0.1220,\n",
      "         -0.1751, -0.1861, -0.0442],\n",
      "        [-0.0795, -0.0977,  0.1117, -0.0756,  0.0644,  0.0334, -0.1375,  0.0481,\n",
      "          0.0871, -0.0133, -0.1403, -0.1398, -0.1892, -0.1191,  0.0890, -0.1631,\n",
      "          0.1856,  0.1755, -0.1235, -0.0524,  0.0912,  0.1459, -0.1824,  0.0826,\n",
      "         -0.0909,  0.1320,  0.1832],\n",
      "        [ 0.1177, -0.1285,  0.1484,  0.1396,  0.1671,  0.1800, -0.1016, -0.0212,\n",
      "         -0.1893, -0.1892,  0.1922,  0.0248,  0.0970,  0.0097,  0.0341, -0.0862,\n",
      "         -0.0189,  0.1876, -0.0817,  0.1390,  0.1051, -0.0090,  0.1720, -0.1330,\n",
      "         -0.0232, -0.0102, -0.0055],\n",
      "        [ 0.0729,  0.1738, -0.1065, -0.1171, -0.0267, -0.1401,  0.0614,  0.0327,\n",
      "          0.0627,  0.0527, -0.1351, -0.0242,  0.0425,  0.1019, -0.1273,  0.1853,\n",
      "         -0.1313,  0.1110,  0.0103, -0.0289, -0.0011,  0.1864,  0.0525,  0.0636,\n",
      "          0.0724,  0.1907, -0.1156],\n",
      "        [ 0.1351, -0.1374, -0.0278, -0.0492,  0.1216,  0.0274, -0.0368, -0.1539,\n",
      "         -0.0993,  0.0694, -0.0307,  0.0984, -0.1227,  0.1497,  0.0025, -0.0135,\n",
      "         -0.0779,  0.0026, -0.0051, -0.0378,  0.1763,  0.1793,  0.1207, -0.1900,\n",
      "          0.1104, -0.0150,  0.0398],\n",
      "        [ 0.1096,  0.1557,  0.1549, -0.1669, -0.0111, -0.1539, -0.0944,  0.1077,\n",
      "         -0.1389, -0.1670, -0.1205,  0.1768,  0.0656, -0.1907,  0.0296,  0.1057,\n",
      "         -0.1875, -0.0527, -0.0085,  0.1891,  0.0076,  0.1821,  0.0888,  0.1073,\n",
      "          0.1270,  0.0220,  0.0331],\n",
      "        [ 0.0689,  0.0962, -0.0637, -0.0122, -0.1571,  0.1864,  0.1456,  0.1710,\n",
      "         -0.0313,  0.0296,  0.1588, -0.0874, -0.1782, -0.0733, -0.1449, -0.1540,\n",
      "          0.0051, -0.1035,  0.1547,  0.1776, -0.0342,  0.1149, -0.0355,  0.1317,\n",
      "          0.1612, -0.0469, -0.1295],\n",
      "        [ 0.0821, -0.0125, -0.1162,  0.1400,  0.1525, -0.1214, -0.0537, -0.1615,\n",
      "         -0.1245,  0.0114,  0.1531, -0.1692,  0.0677, -0.1815, -0.0605,  0.0040,\n",
      "         -0.1456, -0.0999, -0.0253, -0.1765,  0.0769,  0.1300, -0.1601,  0.1909,\n",
      "          0.1410,  0.1850,  0.0460]], requires_grad=True)\n",
      "grad tensor([[-3.5398e-02, -2.2342e-02,  1.6372e-03,  1.4720e-02, -2.8462e-02,\n",
      "         -1.4520e-04, -6.9374e-02, -7.0253e-02, -3.3905e-02,  1.6310e-03,\n",
      "          1.4894e-04,  9.8048e-03,  1.6382e-02,  6.4612e-03,  1.4464e-02,\n",
      "         -9.9315e-03, -9.5215e-03, -7.4931e-04,  2.6004e-02, -9.5826e-03,\n",
      "         -5.7113e-02, -1.7412e-02,  4.1626e-03,  3.0751e-02,  3.0416e-02,\n",
      "          5.1151e-02,  2.0027e-03],\n",
      "        [ 5.3991e-03,  3.4077e-03, -2.4971e-04, -2.2451e-03,  4.3411e-03,\n",
      "          2.2147e-05,  1.0581e-02,  1.0715e-02,  5.1712e-03, -2.4877e-04,\n",
      "         -2.2717e-05, -1.4954e-03, -2.4986e-03, -9.8548e-04, -2.2061e-03,\n",
      "          1.5148e-03,  1.4522e-03,  1.1429e-04, -3.9662e-03,  1.4616e-03,\n",
      "          8.7111e-03,  2.6558e-03, -6.3489e-04, -4.6903e-03, -4.6392e-03,\n",
      "         -7.8017e-03, -3.0546e-04],\n",
      "        [ 3.6997e-03,  2.3351e-03, -1.7112e-04, -1.5384e-03,  2.9747e-03,\n",
      "          1.5176e-05,  7.2506e-03,  7.3425e-03,  3.5436e-03, -1.7047e-04,\n",
      "         -1.5567e-05, -1.0248e-03, -1.7122e-03, -6.7530e-04, -1.5117e-03,\n",
      "          1.0380e-03,  9.9514e-04,  7.8315e-05, -2.7178e-03,  1.0015e-03,\n",
      "          5.9692e-03,  1.8199e-03, -4.3506e-04, -3.2140e-03, -3.1790e-03,\n",
      "         -5.3461e-03, -2.0932e-04],\n",
      "        [ 3.6728e-03,  2.3182e-03, -1.6987e-04, -1.5273e-03,  2.9531e-03,\n",
      "          1.5066e-05,  7.1980e-03,  7.2892e-03,  3.5179e-03, -1.6923e-04,\n",
      "         -1.5454e-05, -1.0173e-03, -1.6997e-03, -6.7040e-04, -1.5007e-03,\n",
      "          1.0305e-03,  9.8792e-04,  7.7747e-05, -2.6981e-03,  9.9427e-04,\n",
      "          5.9259e-03,  1.8067e-03, -4.3190e-04, -3.1907e-03, -3.1559e-03,\n",
      "         -5.3073e-03, -2.0780e-04],\n",
      "        [ 4.0065e-03,  2.5288e-03, -1.8531e-04, -1.6660e-03,  3.2214e-03,\n",
      "          1.6435e-05,  7.8519e-03,  7.9514e-03,  3.8375e-03, -1.8460e-04,\n",
      "         -1.6858e-05, -1.1097e-03, -1.8541e-03, -7.3130e-04, -1.6371e-03,\n",
      "          1.1241e-03,  1.0777e-03,  8.4810e-05, -2.9432e-03,  1.0846e-03,\n",
      "          6.4643e-03,  1.9708e-03, -4.7114e-04, -3.4806e-03, -3.4426e-03,\n",
      "         -5.7894e-03, -2.2668e-04],\n",
      "        [ 4.6656e-03,  2.9448e-03, -2.1579e-04, -1.9401e-03,  3.7514e-03,\n",
      "          1.9138e-05,  9.1436e-03,  9.2595e-03,  4.4687e-03, -2.1497e-04,\n",
      "         -1.9631e-05, -1.2923e-03, -2.1592e-03, -8.5160e-04, -1.9064e-03,\n",
      "          1.3090e-03,  1.2550e-03,  9.8762e-05, -3.4274e-03,  1.2630e-03,\n",
      "          7.5277e-03,  2.2950e-03, -5.4865e-04, -4.0531e-03, -4.0090e-03,\n",
      "         -6.7418e-03, -2.6397e-04],\n",
      "        [ 3.8382e-03,  2.4226e-03, -1.7752e-04, -1.5960e-03,  3.0861e-03,\n",
      "          1.5744e-05,  7.5222e-03,  7.6175e-03,  3.6763e-03, -1.7685e-04,\n",
      "         -1.6150e-05, -1.0631e-03, -1.7763e-03, -7.0059e-04, -1.5683e-03,\n",
      "          1.0769e-03,  1.0324e-03,  8.1248e-05, -2.8196e-03,  1.0390e-03,\n",
      "          6.1928e-03,  1.8880e-03, -4.5135e-04, -3.3344e-03, -3.2980e-03,\n",
      "         -5.5463e-03, -2.1716e-04],\n",
      "        [ 2.9830e-03,  1.8828e-03, -1.3797e-04, -1.2404e-03,  2.3985e-03,\n",
      "          1.2236e-05,  5.8461e-03,  5.9202e-03,  2.8572e-03, -1.3745e-04,\n",
      "         -1.2551e-05, -8.2625e-04, -1.3805e-03, -5.4449e-04, -1.2189e-03,\n",
      "          8.3693e-04,  8.0238e-04,  6.3145e-05, -2.1914e-03,  8.0753e-04,\n",
      "          4.8130e-03,  1.4673e-03, -3.5079e-04, -2.5914e-03, -2.5632e-03,\n",
      "         -4.3105e-03, -1.6877e-04],\n",
      "        [ 5.0581e-03,  3.1925e-03, -2.3394e-04, -2.1033e-03,  4.0669e-03,\n",
      "          2.0748e-05,  9.9128e-03,  1.0038e-02,  4.8446e-03, -2.3306e-04,\n",
      "         -2.1282e-05, -1.4010e-03, -2.3408e-03, -9.2324e-04, -2.0668e-03,\n",
      "          1.4191e-03,  1.3605e-03,  1.0707e-04, -3.7157e-03,  1.3693e-03,\n",
      "          8.1609e-03,  2.4881e-03, -5.9480e-04, -4.3941e-03, -4.3462e-03,\n",
      "         -7.3090e-03, -2.8617e-04],\n",
      "        [ 2.0754e-03,  1.3099e-03, -9.5989e-05, -8.6299e-04,  1.6687e-03,\n",
      "          8.5130e-06,  4.0673e-03,  4.1188e-03,  1.9878e-03, -9.5625e-05,\n",
      "         -8.7323e-06, -5.7484e-04, -9.6044e-04, -3.7881e-04, -8.4800e-04,\n",
      "          5.8227e-04,  5.5823e-04,  4.3931e-05, -1.5246e-03,  5.6182e-04,\n",
      "          3.3485e-03,  1.0209e-03, -2.4405e-04, -1.8029e-03, -1.7833e-03,\n",
      "         -2.9989e-03, -1.1742e-04]])\n",
      "param Parameter containing:\n",
      "tensor([-0.1237,  0.1916,  0.1436, -0.0118,  0.1256,  0.1810,  0.0214, -0.1727,\n",
      "         0.0940, -0.1476], requires_grad=True)\n",
      "grad tensor([-0.0682,  0.0104,  0.0071,  0.0071,  0.0077,  0.0090,  0.0074,  0.0057,\n",
      "         0.0097,  0.0040])\n"
     ]
    }
   ],
   "source": [
    "for param in g.parameters():\n",
    "    print('param', param)\n",
    "    print('grad', param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1631, -0.1311,  0.1842],\n",
      "          [ 0.0904,  0.1047,  0.1307],\n",
      "          [ 0.1567,  0.1591,  0.1095]],\n",
      "\n",
      "         [[ 0.2218, -0.0840,  0.1019],\n",
      "          [-0.1328,  0.0155,  0.0971],\n",
      "          [-0.0611,  0.0068, -0.1498]]],\n",
      "\n",
      "\n",
      "        [[[-0.0038, -0.2094,  0.1477],\n",
      "          [ 0.1900,  0.0107, -0.1863],\n",
      "          [-0.0667, -0.0774, -0.0917]],\n",
      "\n",
      "         [[-0.0670, -0.1002, -0.1774],\n",
      "          [-0.1627, -0.0823,  0.1866],\n",
      "          [-0.0135, -0.1808,  0.0979]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.2074,  0.1376], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([[[[-0.1708,  0.1849, -0.0056],\n",
      "          [-0.0337,  0.1618,  0.0254],\n",
      "          [-0.0699, -0.1940, -0.0088]],\n",
      "\n",
      "         [[ 0.1161,  0.0454, -0.0059],\n",
      "          [-0.0762, -0.2145,  0.0576],\n",
      "          [-0.1632,  0.0411, -0.1934]]],\n",
      "\n",
      "\n",
      "        [[[-0.1760, -0.1316, -0.1121],\n",
      "          [-0.1558,  0.0052,  0.0089],\n",
      "          [-0.1978,  0.0790,  0.2126]],\n",
      "\n",
      "         [[ 0.2056, -0.1163, -0.2354],\n",
      "          [ 0.0843, -0.1891,  0.1142],\n",
      "          [ 0.1834, -0.1979, -0.0405]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.0167, -0.1628], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([[[[-0.1874, -0.2064, -0.0624],\n",
      "          [-0.0998, -0.1766, -0.0843],\n",
      "          [ 0.0578, -0.0292,  0.2088]],\n",
      "\n",
      "         [[-0.0597, -0.1045, -0.0222],\n",
      "          [-0.1618, -0.0224,  0.1637],\n",
      "          [-0.0365, -0.2212,  0.0896]]],\n",
      "\n",
      "\n",
      "        [[[-0.0727, -0.1462, -0.0863],\n",
      "          [-0.1017,  0.0240, -0.0726],\n",
      "          [-0.2075,  0.0152, -0.1354]],\n",
      "\n",
      "         [[-0.2223,  0.1812, -0.2036],\n",
      "          [ 0.0185,  0.0908, -0.1854],\n",
      "          [-0.1499, -0.1653, -0.0046]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.2029, -0.0614], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.1266,  0.2292, -0.1247],\n",
      "          [ 0.1415, -0.0275,  0.0680],\n",
      "          [ 0.1982,  0.1464, -0.1186]],\n",
      "\n",
      "         [[-0.2059,  0.2283,  0.1597],\n",
      "          [-0.0477, -0.0897,  0.2292],\n",
      "          [-0.0200,  0.0425, -0.0915]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0975, -0.0031, -0.0815],\n",
      "          [-0.1942,  0.1720,  0.0151],\n",
      "          [-0.0397, -0.0751, -0.0170]],\n",
      "\n",
      "         [[ 0.2074, -0.0071, -0.1959],\n",
      "          [ 0.0582, -0.0005, -0.2050],\n",
      "          [-0.0732, -0.2225, -0.1801]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([-0.1016, -0.1184], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0839, -0.0330, -0.1818],\n",
      "          [ 0.0761,  0.1142,  0.0622],\n",
      "          [ 0.0850, -0.0234, -0.1332]],\n",
      "\n",
      "         [[ 0.1213,  0.1559,  0.2105],\n",
      "          [-0.0063,  0.2098, -0.1802],\n",
      "          [ 0.0640,  0.0293, -0.1442]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1629,  0.2278, -0.2088],\n",
      "          [-0.1038, -0.0168,  0.0318],\n",
      "          [-0.0097, -0.2205,  0.1773]],\n",
      "\n",
      "         [[ 0.1582, -0.0680,  0.0766],\n",
      "          [-0.1833,  0.1177,  0.1598],\n",
      "          [-0.1722, -0.2053,  0.1188]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([ 0.0093, -0.0124], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0130, -0.1518, -0.1797],\n",
      "          [ 0.0945, -0.0245, -0.0256],\n",
      "          [ 0.0912, -0.0883, -0.1029]],\n",
      "\n",
      "         [[ 0.2032, -0.1417,  0.0466],\n",
      "          [ 0.0931, -0.2349, -0.0325],\n",
      "          [-0.0904, -0.1165,  0.0663]]],\n",
      "\n",
      "\n",
      "        [[[-0.1347, -0.0667, -0.2121],\n",
      "          [ 0.1491,  0.1862,  0.1648],\n",
      "          [ 0.2133, -0.0960, -0.1107]],\n",
      "\n",
      "         [[-0.0777, -0.1126,  0.2324],\n",
      "          [ 0.0098,  0.0054, -0.1215],\n",
      "          [ 0.1064,  0.0763,  0.1532]]]], requires_grad=True)\n",
      "None\n",
      "Parameter containing:\n",
      "tensor([0.0495, 0.0105], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for layer in model.features:\n",
    "    for fn in [layer.f, layer.g]:\n",
    "        for param in fn.parameters():\n",
    "            print(param)\n",
    "            print(param.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (rconv1): ReversibleConv2d(\n",
       "    (f): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (g): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (rconv2): ReversibleConv2d(\n",
       "    (f): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (g): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (rconv3): ReversibleConv2d(\n",
       "    (f): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (g): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=36, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.9269,  1.4873,  0.9007],\n",
      "          [-2.1055,  0.6784, -1.2345],\n",
      "          [-0.0431, -1.6047, -0.7521]],\n",
      "\n",
      "         [[ 1.6487, -0.3925, -1.4036],\n",
      "          [-0.7279, -0.5594, -0.7688],\n",
      "          [ 0.7624,  1.6423, -0.1596]],\n",
      "\n",
      "         [[-0.4974,  0.4396, -0.7581],\n",
      "          [ 1.0783,  0.8008,  1.6806],\n",
      "          [ 1.2791,  1.2964,  0.6105]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3347, -0.2316,  0.0418],\n",
      "          [-0.2516,  0.8599, -1.3847],\n",
      "          [-0.8712, -0.2234,  1.7174]],\n",
      "\n",
      "         [[ 0.3189, -0.4245, -0.8140],\n",
      "          [-0.7360, -0.8371, -0.9224],\n",
      "          [ 1.8113,  0.1606,  0.3672]],\n",
      "\n",
      "         [[ 0.1754, -1.1845,  1.3835],\n",
      "          [-1.2024,  0.7078, -1.0759],\n",
      "          [ 0.5357,  1.1754,  0.5612]]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.randn(2, 3, 3, 3)\n",
    "y = torch.LongTensor([5, 7])\n",
    "\n",
    "print(x)\n",
    "model = Model()\n",
    "criterion = nn.NLLLoss()\n",
    "lr = 0.01\n",
    "n = len(model.features)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    act, logits = model(x)\n",
    "    loss = criterion(logits, y)\n",
    "    loss.backward()\n",
    "\n",
    "    for param in model.classifier.parameters():\n",
    "        param.data -= lr*param.grad\n",
    "        \n",
    "    for i, layer in enumerate(model.features[::-1]):\n",
    "        model.zero_grad()\n",
    "        act = layer.reverse(act)\n",
    "\n",
    "        for j in range(n-i-1, n):\n",
    "            if j == n-i-1:\n",
    "                out = model.features[j].requires_grad_(True)(act, True)\n",
    "            else:\n",
    "                out = model.features[j].requires_grad_(False)(out, True)\n",
    "\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        logits = model.classifier(out)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        for fn in [layer.f, layer.g]:\n",
    "            for param in fn.parameters():\n",
    "                param.data -= lr*param.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.9269,  1.4873,  0.9007],\n",
       "          [-2.1055,  0.6784, -1.2345],\n",
       "          [-0.0431, -1.6047, -0.7521]],\n",
       "\n",
       "         [[ 1.6487, -0.3925, -1.4036],\n",
       "          [-0.7279, -0.5594, -0.7688],\n",
       "          [ 0.7624,  1.6423, -0.1596]],\n",
       "\n",
       "         [[-0.4974,  0.4396, -0.7581],\n",
       "          [ 1.0783,  0.8008,  1.6806],\n",
       "          [ 1.2791,  1.2964,  0.6105]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3347, -0.2316,  0.0418],\n",
       "          [-0.2516,  0.8599, -1.3847],\n",
       "          [-0.8712, -0.2234,  1.7174]],\n",
       "\n",
       "         [[ 0.3189, -0.4245, -0.8140],\n",
       "          [-0.7360, -0.8371, -0.9224],\n",
       "          [ 1.8113,  0.1606,  0.3672]],\n",
       "\n",
       "         [[ 0.1754, -1.1845,  1.3835],\n",
       "          [-1.2024,  0.7078, -1.0759],\n",
       "          [ 0.5357,  1.1754,  0.5612]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 4.0794,  3.6398,  3.0532],\n",
       "           [ 0.0470,  2.8309,  0.9179],\n",
       "           [ 2.1094,  0.5478,  1.4004]],\n",
       " \n",
       "          [[ 2.4458,  0.4046, -0.6065],\n",
       "           [ 0.0692,  0.2376,  0.0282],\n",
       "           [ 1.5595,  2.4394,  0.6375]],\n",
       " \n",
       "          [[ 2.8942,  3.8312,  2.6335],\n",
       "           [ 4.4699,  4.1924,  5.0722],\n",
       "           [ 4.6707,  4.6880,  4.0021]],\n",
       " \n",
       "          [[ 0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 3.7319,  2.1655,  2.4389],\n",
       "           [ 2.1456,  3.2570,  1.0125],\n",
       "           [ 1.5259,  2.1738,  4.1145]],\n",
       " \n",
       "          [[ 1.6706,  0.9272,  0.5377],\n",
       "           [ 0.6157,  0.5146,  0.4293],\n",
       "           [ 3.1630,  1.5123,  1.7190]],\n",
       " \n",
       "          [[ 1.4297,  0.0698,  2.6378],\n",
       "           [ 0.0519,  1.9621,  0.1784],\n",
       "           [ 1.7900,  2.4297,  1.8155]],\n",
       " \n",
       "          [[ 0.4925,  0.4925,  0.4925],\n",
       "           [ 0.4925,  0.4925,  0.4925],\n",
       "           [ 0.4925,  0.4925,  0.4925]]]]),\n",
       " tensor([[3.7283e-04, 2.8809e-04, 1.9712e-04, 9.2073e-05, 1.9263e-04, 9.8737e-01,\n",
       "          2.1109e-04, 1.1071e-02, 1.6387e-04, 4.3621e-05],\n",
       "         [9.2157e-04, 8.8994e-04, 2.1561e-03, 1.1783e-03, 1.7925e-03, 1.3835e-02,\n",
       "          1.6790e-03, 9.7624e-01, 9.0139e-04, 4.0308e-04]],\n",
       "        grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
